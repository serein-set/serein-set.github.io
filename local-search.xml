<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Federated Transfer Learning for IIoT Devices With Low Computing Power Based on Blockchain and Edge Computing</title>
    <link href="/2021/07/20/PaperList-03/"/>
    <url>/2021/07/20/PaperList-03/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h4 id="研究主题"><a href="#研究主题" class="headerlink" title="研究主题"></a><code>研究主题</code></h4><ul><li><strong>DOI：10.1109/ACCESS.2021.3095078</strong></li></ul><p>#####1. 研究主题</p><ul><li><p>需要解决的问题：针对工业物联网设备太低而无法完成联邦学习中模型更新任务的问题。</p></li><li><p>创新点</p><ul><li>针对许多计算能力低下的设备不适合在IIoT中进行联合学习的问题，本文提出了一种将低计算能力设备的数据提交给工厂内网的边缘计算服务器进行训练的策略。</li><li>针对数据传输过程中存在的数据安全问题，本文采用区块链来保护数据的安全</li><li>在工业物联网环境下将联邦学习和迁移学习相结合，以提高训练模型的泛化程度</li></ul></li></ul><h5 id="2-关键技术"><a href="#2-关键技术" class="headerlink" title="2. 关键技术"></a>2. 关键技术</h5><ul><li><p>联邦学习– 保护用户隐私</p></li><li><p>边缘计算–解决设备计算能力不足的问题</p></li><li><p>区块链–保证数据传输的安全性，进行设备认证</p></li><li><p>联邦迁移学习–提高训练模型的效率和通用性</p></li></ul><h5 id="3-相关问题"><a href="#3-相关问题" class="headerlink" title="3. 相关问题"></a>3. 相关问题</h5><ol><li>迁移学习的准确率能再提高吗？</li><li>数据传输的加解密消耗过多资源问题怎么解决？</li></ol><h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a><code>系统架构</code></h4><ul><li>基于区块链的设备身份认证：提出一种工业物联网中的安全传输方案，采用区块链去中心化架构，连续记录进出节点的传输数据，确保数据的安全性。该方案可实现工业物联网设备的身份认证和数据的安全传输，为联邦学习和边缘计算中设备间的数据共享创造条件。</li></ul><ul><li><p>边缘计算：本文提出将物联网中低计算能力设备的数据传输到边缘计算设备上进行训练和更新。该方案提高了联合学习的效率，为IIoT中的联合学习创造了良好的条件。</p></li><li><p>联邦迁移学习：针对工业物联网中性能较低的设备提出了一种合适的联邦迁移学习方法</p></li></ul><h5 id="1-系统设计"><a href="#1-系统设计" class="headerlink" title="1. 系统设计"></a>1. 系统设计</h5><ol><li><p>基于区块链的设备身份认证</p><ol><li><p>区块链系统架构</p><ul><li><p>组成：IIoT设备、边缘服务器和云服务器组成的区块网络。</p></li><li><p>物联网设备节点不承担数据计算工作，我们让现有的云服务器作为创建节点。</p></li><li><p>共识算法：Ripple算法</p></li><li><p>当一个节点发起申请时，验证节点将验证该节点的身份，如果验证通过则签名。当整个区块链系统的签名数不低于当前区块链系统汇总数的51%时，当前区块链系统认为该节点已通过区块链系统的审核。否则这个请求将被丢弃。</p></li><li><p>交易：包括设备类型、数据内容、数据、数据生成时间、处理节点和处理节点签名</p></li></ul></li><li><p>身份验证过程</p><ul><li>IIoT设备认证方案：集中式密钥分发改进方案，其主要功能是数字证书的颁发和管理。</li><li>利用云服务器作为密钥分发中心，通过协商机制对密钥进行分发和管理。</li><li>举例：注册<ol><li>首先，物联网设备向云服务器申请注册</li><li>云服务器通过共识机制检查物联网设备的身份</li><li>审批通过后，云服务器将生成包含当前设备公钥的数字证书，并将其记录到自己的账簿中。</li><li>然后云服务器将设备的信息发送到区块链中的其他节点。</li><li>其他节点只需要验证证书的有效性，就可以知道当前记录的有效性。</li><li>验证后，其他节点将记录在各自的账簿中</li></ol></li></ul></li></ol></li><li><p>边缘计算</p><ul><li><p>目的：解决IIoT中计算能力的不足的问题</p></li><li><p>过程：</p><ol><li><p>当需要训练时，设备将自己的<strong>数据</strong>和自己的<strong>设备编号</strong>  <strong>分批上传</strong> 到每个厂内配备的边缘服务器。</p></li><li><p>边缘服务器使用Quicksort对所有数据进行<strong>排序</strong>，对排序后的数据进行<strong>比较</strong>，并<strong>删除重复的数据</strong>。</p></li><li><p>在边缘服务器对设备传输的数据进行<strong>训练</strong>后，边缘服务器将把当前工厂中<strong>同类型设备</strong>的模型<strong>合并为一个模型进行训练</strong>。</p><ul><li><p>边缘计算设备位于工厂内网中，以确保数据的隐私和安全</p></li><li><p>对工厂内同类型设备的模型进行合并更新后，可以大大减少对公共网络带宽的占用，提高联邦学习的效率。</p></li></ul></li><li><p>最后，合并后的训练模型被<strong>上传到云服务器</strong>，云服务器返回的模型被<strong>分发到各设备</strong>。</p></li></ol></li></ul></li><li><p>联邦迁移学习模型</p><ul><li>无监督领域自适应训练的过程通常分为两部分：预训练和微调。<ol><li>首先，在源域对特征提取器和分类器进行预训练</li><li>然后，源域将特征提取器的权重发送给目标域，并为两者之间的合作微调阶段做准备。</li><li>在微调阶段，每批数据的处理可以分为四个步骤：前馈、分类损失函数和梯度计算、MMD损失函数和梯度计算、模型参数更新。</li></ol></li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720202324.png"></p></li></ol><h5 id="2-实验部分"><a href="#2-实验部分" class="headerlink" title="2. 实验部分"></a>2. 实验部分</h5><ul><li>实验目的：验证区块链认证系统的安全性、联邦学习的准确性和迁移学习的准确性</li></ul><ol><li><p>基于区块链的设备身份认证实验</p><ol><li><p>网络流量测试</p><ul><li>目的：测试该协议与未经认证的无线接入点之间的网络流量的差异，从而测量协议造成的网络流量压力的增加</li><li>测试方法：使用 iftop 对网络流量进行测试，将直接发送到区块链的查询请求与本协议认证的请求流量进行比较，不断改变每秒查询次数（QPS），计算出网络流量利用率。</li><li>为了及时响应请求，更准确地测量对网络的影响，随机选择的服务节点的数量为1，在这种情况下，不需要运行共识协议。</li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720210513.png"></p><ul><li>结论：该方案对网络流量的影响为千分之一，对程序网络性能的影响可以忽略不计</li></ul></li><li><p>安全分析</p><ul><li><strong>伪装攻击测试</strong>：使用与用户地址不匹配的私钥对数据包进行签名，然后发送到无线接入点。接入点成功丢弃报文</li><li><strong>伪造攻击测试</strong>：对于中间人和未经认证的攻击，该解决方案依靠数字签名技术，在所有阶段都能有效防止。由于攻击者不能通过共识认证，他不能加入区块链，更不用说创建请求交易了。</li><li><strong>重放攻击测试</strong>：同一个数据包被发送到无线接入点两次，无线接入点只向区块链发出一次请求。</li><li><strong>拒绝服务攻击</strong>：本文提出的算法可以保证用户和无线接入点不能操纵参与协商验证的节点，从而保证验证流量不能集中在少数节点上，并在一定程度上限制拒绝服务攻击</li></ul></li></ol></li><li><p>联邦学习的实验</p><ul><li><p>数据集：KDD99数据集</p></li><li><p>实验设置：四个终端和一个云服务器，每个终端有10%的随机抽取的KDD99数据，保证了四个终端存储的数据基本不同</p></li><li><p>对照试验：本文算法与CSE、GRAE和FedAvg进行比较</p></li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720212655.png"></p><ul><li>结论：<ul><li>对于KDD99数据集：本文提出的联邦学习方法在所有学习类型中表现最好。这主要是由于一般集中学习方法不能很好地更新模型，受限于有限的训练数据集，不能产生良好的效果。另一方面，标准联邦学习方法在本文描述的环境中受到设备有限计算能力的限制，可能会对模型产生负面影响，影响模型的准确性</li></ul></li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720213828.png"></p><ul><li>结论：<ul><li>本文提出的联合学习算法比其他算法具有更高的准确率。验证了低计算功率设备在工业物联网中参与联邦学习的可行性</li></ul></li></ul></li><li><p>迁移学习实验</p><ul><li>数据集：KDD99数据集</li><li>实验设置：每个设备设置了不同的数据集。将10%的KDD99数据集划分为五个部分:Normal、DOS、Probe、R2L和U2R，并将它们放在不同的节点上。</li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720214332.png"></p><ul><li>结论：本文提出的算法取得了较好的迁移学习准确率</li></ul></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Federated Transfer Learning</tag>
      
      <tag>Edge computing</tag>
      
      <tag>Blockchain</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FedHealth:A Federated Transfer Learning Framework for Wearable Healthcare</title>
    <link href="/2021/07/19/PaperList-02/"/>
    <url>/2021/07/19/PaperList-02/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h4 id="研究主题"><a href="#研究主题" class="headerlink" title="研究主题"></a><code>研究主题</code></h4><ul><li><strong>DOI：10.1109/MIS.2020.2988604</strong></li></ul><h5 id="1-研究主题"><a href="#1-研究主题" class="headerlink" title="1. 研究主题"></a>1. 研究主题</h5><ul><li><p>为了解决数据孤岛和个性化模型训练问题，提出了一个联邦迁移学习框架FedHealth用于可穿戴医疗保健。</p></li><li><p>创新点</p></li><li><ul><li><p>第一个将联邦迁移学习用于可穿戴健康的工作</p></li><li><p>保障隐私安全的情况下聚合数据</p></li><li><p>实现相对个性化的模型学习</p></li></ul></li></ul><h5 id="2-关键技术"><a href="#2-关键技术" class="headerlink" title="2. 关键技术"></a>2. 关键技术</h5><ul><li>联邦学习–解决数据孤岛问题</li><li>迁移学习–解决个性化模型学习问题<ul><li>其他方法：<strong>增量学习</strong>能够随着时间、环境和用户的逐渐变化而更新模型。与侧重于模型适应的迁移学习相比，增量学习使在新用户数据到达时无需大量计算就可以实时更新模型成为可能</li></ul></li></ul><h5 id="3-相关问题"><a href="#3-相关问题" class="headerlink" title="3. 相关问题"></a>3. 相关问题</h5><ol><li>在什么阶段聚合？更新的频率和大小是多少？</li><li>如何提高计算效率？</li><li>模型更新聚合的开销十分消耗资源该怎么解决？</li><li>每次模型聚合的延迟如何？</li></ol><h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a><code>系统架构</code></h4><p>​    <img src="https://gitee.com/serein-set/pic/raw/master/20210720101821.png" alt="image-20210720101821486"/></p><ul><li><p>FedHealth工作过程</p><ol><li><p>首先，服务器端的云模型是基于公共数据集训练的</p></li><li><p>然后，云模型被分发到所有的用户，每个人都可以在他们的数据上训练自己的模型。</p></li><li><p>随后，用户模型可以被上传到云端，以帮助训练新的云模型。</p><ul><li><strong>注</strong>：这一步<strong>不会分享任何用户数据或信息</strong>，而是分享加密的模型参数</li></ul></li><li><p>最后，每个用户可以通过整合云模型和其以前的模型和数据来训练个性化的模型–迁移学习</p></li></ol><ul><li><strong>注</strong>：同态加密保证了所有的参数共享过程都不涉及任何用户数据的泄露</li></ul></li></ul><h5 id="1-FeaHealth学习算法"><a href="#1-FeaHealth学习算法" class="headerlink" title="1. FeaHealth学习算法"></a>1. FeaHealth学习算法</h5><ul><li><p>关键部分：云和用户模型学习</p></li><li><p>迁移学习过程</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720103022.png"></p><ul><li><p>参数共享时如何提高计算效率？</p><ul><li>对于聚合，服务器可以随后将旧模型与来自每个用户的模型对齐。</li><li>服务器也可以通过上传用户模型实现定时更新</li></ul></li><li><p>如何解决个性化问题？</p><ul><li><p>一般模型的泛化性能差：原因是用户和云数据之间的分布差异造成的。服务器中的公共模型只学习所有用户的粗特征，而不能学习特定用户的细粒度信息</p></li><li><p>解决办法：Federhealth使用迁移学习为每个用户构建个性化模型–CNN</p></li></ul></li></ul></li><li><p>CNN模型</p><ul><li><p>构成</p><ul><li>两个卷积层(conv1,  conv2) : 提取活动识别的低级特征</li><li>两个最大池层(pool1,  pool2)<ul><li>卷积层和最大池层在反向传播中<strong>不更新</strong>参数</li></ul></li><li>两个全连接层(fc1,  fc2) : 学习任务和用户的具体特征<ul><li>通过将fc2替换为<strong>对齐层</strong>，<strong>FedHealth可以调整来自不同域的输入</strong></li><li>在训练中需要<strong>更新</strong>的参数</li></ul></li><li>一个用于分类的softmax层</li></ul></li><li><p>此处的模型用于人类活动识别</p><ul><li>输入数据是用户的活动信号</li><li>输出是用户的活动类</li></ul></li></ul></li></ul><ul><li><p>FedHealth 学习算法</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720102920.png"></p><ul><li><p>相关公式</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720103323.png"></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720103348.png"></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720103403.png"></p></li><li><p>注 : 这个框架不断地与新出现的用户数据一起工作。当面对新的用户数据时，federhealth可以同时更新用户模型和云模型。因此，用户使用产品的时间越长，模型就可以越个性化</p></li></ul></li></ul><h5 id="2-实验部分"><a href="#2-实验部分" class="headerlink" title="2. 实验部分"></a>2. 实验部分</h5><p>​    <img src="https://gitee.com/serein-set/pic/raw/master/20210720112601.png"></p><p>​    <img src="https://gitee.com/serein-set/pic/raw/master/20210720112235.png"></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720112304.png"></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720112423.png"></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210720112631.png"></p><ul><li><p>结论</p><ul><li><p>Extensibility With Alternative Transfer Learning Methods:在大多数情况下，Federhealth使用调优或MMD都可以取得令人满意的结果，这表明FedHealth在实际应用中与其他传输学习算法是有效的和可扩展的</p></li><li><p>Ablation Study : 联邦学习结合迁移学习，每个用户模型都可以获得更好的分类性能。原因:</p><ul><li>通过联邦学习，服务器可以间接利用来自多个用户的更多信息，从而获得更一般化的云模型</li><li>通过迁移学习，用户可以利用云模型获得更个性化的用户模型</li></ul></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Federated Transfer Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Client-Edge-Cloud Hierarchical Federated Learning</title>
    <link href="/2021/07/18/PaperList-01/"/>
    <url>/2021/07/18/PaperList-01/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><h4 id="研究主题"><a href="#研究主题" class="headerlink" title="研究主题"></a><code>研究主题</code></h4><ul><li><strong>DOI：10.1109/ICC40277.2020.9148862</strong></li></ul><h5 id="1-研究主题"><a href="#1-研究主题" class="headerlink" title="1. 研究主题"></a>1. 研究主题</h5><ul><li>本文针对FedAvg算法带来的大量的通讯开销和边缘计算提出了一种新的结构（客户端-边缘-云端分层的联邦学习系统）以及HierFAVG算法</li><li>创新点<ul><li>HierFAVG算法允许多个边缘服务器执行部分模型聚合。通过这种方式，模型可以被更快地训练，并且可以实现更好的通信-计算权衡</li><li>引入客户端-边缘-云端分层的联邦学习系统，首先在中间边缘服务器进行边缘的局部聚合，再在云端进行全局聚合，减少模型训练时间和终端设备的能量消耗</li></ul></li></ul><h5 id="2-关键技术"><a href="#2-关键技术" class="headerlink" title="2. 关键技术"></a>2. 关键技术</h5><ul><li>收敛性分析<ul><li>目标：证明真正的权值w(k)与虚拟集中序列u{q}(k)没有太大的偏差</li><li>关键点：证明真正的权值w(k)与虚拟集中序列u{q}(k)没有太大的偏差</li><li>注：数据是由每个客户端单独生成的，本地数据分布可能不均衡，非iid数据分布[14]会严重影响模型性能</li><li>结论<ul><li><strong>频繁的局部模型平均化可以减少所需的局部迭代次数</strong></li><li><strong>可用于减少与云端通信的方法：使边缘数据集的分布达到IID</strong></li></ul></li></ul></li><li>HierFAVG算法</li></ul><h5 id="3-相关问题"><a href="#3-相关问题" class="headerlink" title="3. 相关问题"></a>3. 相关问题</h5><p>​    1. 将FAVG算法扩展到层次设置，新算法还会收敛吗?</p><p>​    2. 给定了模型聚合的两个级别(一个在边缘，一个在云)，在每个级别上模型聚合的频率应该是多少?</p><p>​    3. 通过允许频繁的本地更新，可以实现更好的延迟-能量权衡吗?</p><p>####<code>系统架构</code></p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210718204716.png"></p><ul><li><p>与cloud-based相比，client-edge-cloud优势：减少与云的昂贵通信，并辅以高效的客户端边缘更新，从而显著减少运行时间和本地迭代的数量</p></li><li><p>与edge-based相比：分层的FL在模型训练方面将优于基于边缘的FL</p></li></ul><h5 id="1-HierFAVG算法-–Client-Edge-Cloud-分层联邦学习"><a href="#1-HierFAVG算法-–Client-Edge-Cloud-分层联邦学习" class="headerlink" title="1. HierFAVG算法 –Client-Edge-Cloud 分层联邦学习"></a>1. HierFAVG算法 –Client-Edge-Cloud 分层联邦学习</h5><ul><li><p>关键步骤：</p><ul><li>局部聚合–边缘–每个边缘间隔的末端：在每个client的每κ1次本地更新后，每个边缘服务器都会聚合其clients的模型。</li><li>全局聚合–云–每个云间隔的末端：然后在每κ2个边缘模型聚合后，云服务器会聚合所有边缘服务器的模型，这意味着与云的通信每 κ1κ2 个本地更新发生一次</li></ul></li><li><p>算法</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210718211838.png"></p></li><li><p>HierFAVG和FAVG比较</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210718211937.png"></p></li></ul><h5 id="2-实验部分"><a href="#2-实验部分" class="headerlink" title="2. 实验部分"></a>2. 实验部分</h5><ul><li>实验重点：与基于云的FL系统进行比较</li></ul><ol><li><p>系统设置与假设</p><ul><li><p>假设每个边缘服务器用相同数量的训练数据授权给相同数量的客户。我们拥有50个客户端、5个边缘服务器和一个云服务器的分层FL系统</p></li><li><p>任务：图像分类任务–CNN </p></li><li><p>梯度下降法：批量大小为20的小批量随机梯度下降(SGD)</p></li><li><p>数据集：标准数据集MNIST和CIFAR-10</p><ul><li><p>MNIST：– 21840个可训练参数</p><ul><li>初始学习率为0.01，并以0.995的速率随每个epoch衰减</li><li>以下两种MNIST非iid情况:<ol><li>Edge-IID：为每个客户端分配一个类的样本，并为每个边缘分配10个不同类别的客户。边缘之间的数据集是IID的</li><li>Edge-NIID：每个客户端分配一个类别的样本，给每个边缘分配10个客户，共5个类别的标签。边缘之间的数据集为non-IID。</li></ol></li></ul></li><li><p>CIFAR-10：– 5852170个参数 – 3个卷积块</p><ul><li>初始学习率为0.1，并以0.992的速率随每个epoch衰减</li></ul></li></ul></li></ul></li></ol><ol start="2"><li><p>结果</p><p><img src="https://gitee.com/serein-set/pic/raw/master/20210719164003.png"></p><ul><li><strong>结论</strong>1<ul><li>与云的通信频率固定(即κ1· κ2固定)时，与边缘的通信越频繁(即较少的局部更新κ1)，训练过程就越快。</li><li>将与云服务器的通信频率固定在60次局部迭代时，即κ1κ2=60，并改变κ1的值。对于两种non-IID数据分布，当我们减小k1时，只需较少的训练次数就可以达到预期的精度，这意味着在设备上需要较少的本地计算。</li><li>当边缘之间的数据集是IID且与边缘服务器的通信频率固定时，降低与云服务器的通信频率不会减慢训练过程</li><li>对于Edge-NIID，当κ1=  60时，增大κ2会使训练过程变慢。在Edge-IID场景下，我们可能能够进一步减少与云的高成本通信，而性能损失很小。</li></ul></li></ul><p><img src="https://gitee.com/serein-set/pic/raw/master/20210719164214.png"></p><ul><li><strong>结论2</strong><ul><li>分层FL比基于云的FL在训练时间上有很大优势：对于MNIST和CIF AR-10数据集，随着我们增加与边缘服务器的通信频率（即κ2），达到一定测试精度的训练时间单调地<strong>减少</strong></li><li>对于本地能源消耗，它首先减少，然后随着κ2的增加而增加。因为<strong>适度增加客户端与边缘的通信频率可以减少消耗的能量</strong>，因为需要的本地计算较少。但是过于频繁的边缘-客户通信也会消耗额外的能量用于数据传输。如果目标是最小化设备能耗，我们应该通过调整κ1、κ2来仔细平衡计算和通信能量</li></ul></li></ul></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Edge Learning</tag>
      
      <tag>Federated Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
